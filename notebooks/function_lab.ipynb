{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760d84e3-faa3-4141-bf6b-fb08ed552a40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-aiplatform==1.60.0\n",
      "  Downloading google_cloud_aiplatform-1.60.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.60.0) (2.35.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.60.0) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.60.0) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.60.0) (24.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.60.0) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.60.0) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.60.0) (1.12.5)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.60.0) (2.0.6)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.60.0) (2.9.2)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.60.0) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0) (1.66.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.60.0) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.60.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.60.0) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.60.0) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.60.0) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.60.0) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.60.0) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.60.0) (1.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform==1.60.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform==1.60.0) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform==1.60.0) (4.12.2)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform==1.60.0) (1.26.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.60.0) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.60.0) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0) (2024.8.30)\n",
      "Downloading google_cloud_aiplatform-1.60.0-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-cloud-aiplatform\n",
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed google-cloud-aiplatform-1.60.0\n"
     ]
    }
   ],
   "source": [
    "! pip3 install --upgrade --user google-cloud-aiplatform==1.60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e7829dfc-45ef-460b-ae98-23ea8110355c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af5e8fb-ade3-4207-be4f-34d4a0d9882b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwiklabs-gcp-03-480091a802dc\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "\n",
    "PROJECT_ID = ! gcloud config get-value project\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
    "\n",
    "print(PROJECT_ID)\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bbef4fb-7b9c-4db8-a4aa-5286028e4f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from vertexai.generative_models import (\n",
    "    Content,\n",
    "    FunctionDeclaration,\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    Tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7928b48-e0ca-4a81-8968-d64b560ff304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Define a function to add two numerical inputs and return the result.\n",
    "# Keep the print statement within the function.\n",
    "\n",
    "def add_numbers(a, b):\n",
    "    print(\"Calling add function\")\n",
    "    return a + b\n",
    "\n",
    "# TODO: Define a function to multiply two numerical inputs and return the result.\n",
    "# Keep the print statement within the function.\n",
    "\n",
    "def multiply_numbers(a, b):\n",
    "    print(\"Calling multiply function\")\n",
    "    return a * b\n",
    "\n",
    "# TODO: Create FunctionDeclarations for your functions\n",
    "\n",
    "add_function_declaration = FunctionDeclaration(\n",
    "    name=\"add_numbers\",\n",
    "    description=\"Adds two numbers together.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"The first number to add.\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"The second number to add.\"}\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "multiply_function_declaration = FunctionDeclaration(\n",
    "    name=\"multiply_numbers\",\n",
    "    description=\"Multiplies two numbers together.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"The first number to multiply.\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"The second number to multiply.\"}\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"]\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41860def-a83f-4d9e-bd17-4f48c335f34b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add_function_declaration = FunctionDeclaration.from_func(add_numbers)\n",
    "\n",
    "# multiply_function_declaration = FunctionDeclaration.from_func(multiply_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eef202e5-a97b-4de2-9f91-ba54d116ce6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "math_tool = Tool(\n",
    "    function_declarations=[\n",
    "        add_function_declaration,\n",
    "        multiply_function_declaration\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81909a47-05dd-4a48-9d14-762a61817d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro-001\",\n",
    "    generation_config=GenerationConfig(temperature=0),\n",
    "    tools=[math_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5d5302b-f2a1-42cd-b1f7-f9bda672768c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the user's prompt in a Content object that we can reuse in model calls\n",
    "user_prompt_content = Content(\n",
    "    role=\"user\",\n",
    "    parts=[\n",
    "        Part.from_text(\"\"\"\n",
    "    You are a helpful assistant.\n",
    "\n",
    "    - Fulfill the user's instructions.\n",
    "    - If asked to add or multiply numbers, call the provided functions.\n",
    "    - You may call one function after the other if needed.\n",
    "    - Repeat the result to the user.\n",
    "    \"\"\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "347bf92c-dcb5-4840-9f9e-2540857a6ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d208c3c-1c0b-4921-9e6f-127afaf41d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = chat.send_message(\"multiply 7 and 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd0cc7dd-5227-44d2-b4fe-200f93d8069b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = chat.send_message(\"\"\"\n",
    "    You are a helpful assistant.\n",
    "\n",
    "    - Fulfill the user's instructions.\n",
    "    - If asked to add or multiply numbers, call the provided functions.\n",
    "    - You may call one function after the other if needed.\n",
    "    - Repeat the result to the user.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33174ada-74d1-494b-9584-af097416e826",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"Sounds like a plan! I\\'m ready to assist you with adding and multiplying numbers. Just let me know what you need. \\360\\237\\230\\212 \\n\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.07470703125\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.06640625\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.1396484375\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.119140625\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.0673828125\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.053466796875\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.08056640625\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.054931640625\n",
       "  }\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 356\n",
       "  candidates_token_count: 29\n",
       "  total_token_count: 385\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83f049a8-35d6-4d60-a631-5c038f3f4bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_response(response):\n",
    "    # If there is a function call then invoke it\n",
    "    # Otherwise, print the response.\n",
    "    if response.candidates[0].function_calls:\n",
    "        function_call = response.candidates[0].function_calls[0]\n",
    "    else:\n",
    "        print(response.text)\n",
    "        return\n",
    "    \n",
    "    # Extract the function name\n",
    "    function_name = function_call.name\n",
    "    \n",
    "    # Complete the following sections\n",
    "    if function_name == \"add_numbers\":\n",
    "        # Extract the arguments to use in your function\n",
    "        arguments = function_call.args\n",
    "        # Assuming arguments are in JSON string format\n",
    "        args = arguments\n",
    "        a = args.get(\"a\")\n",
    "        b = args.get(\"b\")\n",
    "        # Call your function\n",
    "        result = add_numbers(a, b)\n",
    "        # Send the result back to the chat session with the model\n",
    "        new_response = chat.send_message(str(result))\n",
    "        # Make a recursive call of this handler function\n",
    "        handle_response(new_response)\n",
    "    \n",
    "    elif function_name == \"multiply_numbers\":\n",
    "        # Extract the arguments to use in your function\n",
    "        arguments = function_call.args\n",
    "        # Assuming arguments are in JSON string format\n",
    "        args = arguments\n",
    "        a = args.get(\"a\")\n",
    "        b = args.get(\"b\")\n",
    "        # Call your function\n",
    "        result = multiply_numbers(a, b)\n",
    "        # Send the result back to the chat session with the model\n",
    "        new_response = chat.send_message(str(result))\n",
    "        # Make a recursive call of this handler function\n",
    "        handle_response(new_response)\n",
    "\n",
    "    else:\n",
    "        # You shouldn't end up here\n",
    "        print(f\"Unexpected function call: {function_call.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28563d95-6aa4-4a4c-a7ba-70a8c3258022",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sounds like a plan! I'm ready to assist you with adding and multiplying numbers. Just let me know what you need. üòä \n",
      "\n"
     ]
    }
   ],
   "source": [
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39ab6f9e-d7c9-4da3-83d5-47b746bf0bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't they play poker in the jungle? \n",
      "\n",
      "Too many cheetahs! üòâ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Tell me a joke.\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12ee45d8-5e02-4122-93f9-602509d20d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling multiply function\n",
      "You have 112.0 slices. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"I have 7 pizzas each with 16 slices. How many slices do I have?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1739b281-7289-44af-a8e5-36b81be604e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function\n",
      "They brought 7.0 pizzas together. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 3 pizzas. Andrew brought 4 pizzas. How many pizzas did they bring together?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f594ada4-0128-4b9b-9e68-092d63caf245",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function\n",
      "Calling multiply function\n",
      "There are 112.0 slices. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 3 pizzas. Andrew brought 4 pizzas. There are 16 slices per pizza. How many slices are there?\")\n",
    "handle_response(response)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83654001-62bd-42cb-9d4c-fe50cbb64194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function\n",
      "There are 2.0 pizzas left. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 4 pizzas, but Andrew dropped 2 on the ground. How many pizzas are left?\")\n",
    "handle_response(response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb474a1-a0b3-421e-bde8-3b004cb799f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
