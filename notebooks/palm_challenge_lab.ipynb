{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# PaLM Challenge Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK1Q5ZYdVL4Y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "You've just spent some time running through many of the elements related to Google's PaLM API, its use and its API. This challenge lab is designed to test your knoledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQT500QqVPIb",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Objectives\n",
    "\n",
    "- Load the Vertex AI language models\n",
    "- Authenticate your environment\n",
    "- Demonstrate the use of prompt design, ideation, text classification, and text extraction\n",
    "\n",
    "Most of the following Python notebook cells have missing or incomplete code sections. Your challenge is to complete each cell, run it to test for correctness, and then move on. When all the cells are working, you have completed the challenge.\n",
    "\n",
    "**Note: The notebooks used in the PaLM labs may all be viewed directly on Github [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDU0XJ1xRDlL"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5afkyDMSBW5"
   },
   "source": [
    "### Install Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kc4WxYmLSBW5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.60.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.64.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.32.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.5)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.5)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.17)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.1)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.25.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.7.4)\n",
      "Downloading google_cloud_aiplatform-1.64.0-py2.py3-none-any.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-cloud-aiplatform\n",
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed google-cloud-aiplatform-1.64.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Complete the following pip command\n",
    "!pip install google-cloud-aiplatform --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart your notebook Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Fom0ZkMSBW6"
   },
   "source": [
    "### Authenticating your notebook environment\n",
    "* Use the instructions found [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env) in the block below, insert the lines required to set the project ID and location (us-central1 works for sure) variables. Then import and initialize the vertexai library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LCaCx6PLSBW6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insert the requisite steps here\n",
    "import vertexai\n",
    "\n",
    "PROJECT_ID = \"qwiklabs-gcp-02-5336633527c1\"  # @param {type:\"string\"}\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuQwwRiniVFG"
   },
   "source": [
    "### Import libraries\n",
    "Import the following language model classes:\n",
    "- ChatModel\n",
    "- InputOutputTextPair\n",
    "- TextEmbeddingModel\n",
    "- TextGenerationModel\n",
    "\n",
    "from the Vertex AI, preview, language models module. \n",
    "\n",
    "For display purposes, also import Markdown and display from IPython display. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4zjV4alsiVql",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Complete the two imports\n",
    "from vertexai.preview.language_models import ( \n",
    "    ChatModel,\n",
    "InputOutputTextPair,\n",
    "TextEmbeddingModel,\n",
    "TextGenerationModel,\n",
    ")\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting Google's PaLM technology to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4437b7608c8e"
   },
   "source": [
    "#### Load the model\n",
    "\n",
    "Instantiate a TextGenerationModel and save it to the `generation_model` variable. For this notebook, use `text-bison@002` as your model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2998506fe6d1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724821248.572243     767 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n"
     ]
    }
   ],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEAJ0ipmbndQ"
   },
   "source": [
    "### Prompt design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCgBDJvNRCF5"
   },
   "source": [
    "Create a prediction around the prompt, \"Tell me about Google's PaLM API.\" Set the `temperature` to 0 and and set the `max_output_tokens` for the longest response possible with the text-bison@002 model. Leave the top_k and top_p with their defaults. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cx_o455SRCF5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The PaLM API (Pathways Language Model) is a large language model developed by Google AI. It is a transformer-based language model that has been trained on a massive dataset of text and code. PaLM stands for Pathways Language Model, and it is part of Google's Pathways project, which aims to develop a unified AI architecture that can be used for a wide range of tasks.\n",
      "\n",
      "PaLM is a very powerful language model, and it has been shown to achieve state-of-the-art results on a variety of natural language processing tasks, including text generation, translation, question answering, and summarization. PaLM is also able to generate code, and it has been used to develop new software applications.\n",
      "\n",
      "The PaLM API is available to developers through Google Cloud Platform. Developers can use the API to access PaLM's language processing capabilities and to build their own AI applications. The API is still in beta, but it is already being used by a number of companies and organizations to develop new products and services.\n",
      "\n",
      "Here are some of the key features of the PaLM API:\n",
      "\n",
      "* **Large-scale:** PaLM is trained on a massive dataset of text and code, which gives it a deep understanding of language and the ability to generate high-quality text.\n",
      "* **Versatile:** PaLM can be used for a wide range of natural language processing tasks, including text generation, translation, question answering, and summarization.\n",
      "* **Powerful:** PaLM is a very powerful language model, and it has been shown to achieve state-of-the-art results on a variety of natural language processing tasks.\n",
      "* **Accessible:** The PaLM API is available to developers through Google Cloud Platform, making it easy for developers to build their own AI applications.\n",
      "\n",
      "The PaLM API is a powerful tool that can be used to develop a wide range of AI applications. As the API continues to develop, it is likely to become even more powerful and versatile, making it an even more valuable tool for developers.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Tell me about Google's PaLM API.\"\"\"\n",
    "\n",
    "response = generation_model.predict(\n",
    "        prompt=prompt,\n",
    "        max_output_tokens=1024,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsglQtgDRCF5"
   },
   "source": [
    "### Ideation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BP1BKWiRCF6"
   },
   "source": [
    "Use the below template to get your model to give you 5 title ideas for a training course on Google's Generative AI technologies. Once again, set the model’s prediction temperature to 0. \n",
    "\n",
    "Use display and Markdown to render the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2USfPyOuFhlB",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Training Course Title Ideas:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\" 1. **Unlocking the Power of Google's Generative AI: A Comprehensive Guide**\\n2. **Mastering Google's Generative AI: From Basics to Advanced Applications**\\n3. **Harnessing the Potential of Google's Generative AI for Business Growth**\\n4. **Exploring the Creative Possibilities with Google's Generative AI**\\n5. **Demystifying Google's Generative AI: A Hands-On Approach**\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Give me 5 title ideas for a training course on Google's Generative AI technologies\"\"\"\n",
    "\n",
    "response = generation_model.predict(prompt=prompt,\n",
    "        max_output_tokens=1024,\n",
    "        temperature=0,)\n",
    "\n",
    "# Display the results using Markdown\n",
    "display(\"### Training Course Title Ideas:\")\n",
    "display(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification\n",
    "Let's try a language classification problem. Using the below starting code, determine the language of: \"Es viernes todavía.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt = \"\"\"\n",
    "Given ...\n",
    "text: ...\n",
    "language:\n",
    "\"\"\"\n",
    "\n",
    "# add code to print the prediction using the defaults for temperature, max output tokens, top_p and k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are a little wordy, use one-shot prompting to get the prediction to return a single word to you, the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " text: Guten Tag!\n",
      "language: German\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Given the following text, classify the language it is written in.\n",
    "\n",
    "text: Es viernes todaví?\n",
    "language: Spanish\n",
    "\n",
    "text: How are you?\n",
    "language:\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt=prompt\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Extraction\n",
    "Print the following list of cooking ingredients to a YAML format. Each ingredient should be listed with keys for **ingredient** and **quantity**, with each key having the correct value given the ingredients in the following recipe:\n",
    "\n",
    "Ingredients\n",
    "* 9 egg whites\n",
    "* 3/8 tsp Cream of Tartar\n",
    "* 1 1/2 tbs Vinegar\n",
    "* 1 1/2 tsp Vanilla\n",
    "* 3 cups Sugar\n",
    "* 1 quarts Heavy whipping cream\n",
    "* 3 boxes Strawberries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---\n",
      "Ice Cream Recipe:\n",
      "ingredients:\n",
      "  - ingredient: egg whites\n",
      "    quantity: 9\n",
      "  - ingredient: Cream of Tartar\n",
      "    quantity: 3/8 tsp\n",
      "  - ingredient: Vinegar\n",
      "    quantity: 1 1/2 tbs\n",
      "  - ingredient: Vanilla\n",
      "    quantity: 1 1/2 tsp\n",
      "  - ingredient: Sugar\n",
      "    quantity: 3 cups\n",
      "  - ingredient: Heavy whipping cream\n",
      "    quantity: 1 quarts\n",
      "  - ingredient: Strawberries\n",
      "    quantity: 3 boxes\n",
      "\n",
      "Thanksgiving Dinner Recipe:\n",
      "ingredients:\n",
      "  - ingredient: Turkey\n",
      "    quantity: 1\n",
      "  - ingredient: Stuffing\n",
      "    quantity: 1 box\n",
      "  - ingredient: Mashed potatoes\n",
      "    quantity: 5 lbs\n",
      "  - ingredient: Gravy\n",
      "    quantity: 1 jar\n",
      "  - ingredient: Cranberry sauce\n",
      "    quantity: 1 can\n",
      "  - ingredient: Green bean casserole\n",
      "    quantity: 1 can\n",
      "  - ingredient: Dinner rolls\n",
      "    quantity: 1 dozen\n",
      "  - ingredient: Butter\n",
      "    quantity: 1 lb\n",
      "  - ingredient: Pumpkin pie\n",
      "    quantity: 1\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Print the following list of cooking ingredients to a YAML format. Each ingredient should be listed with keys for ingredient and quantity, with each key having the correct value given the ingredients in the following recipe:\n",
    "\n",
    "Text: Ice Cream Recipe\n",
    "\n",
    "ingredients:\n",
    "  - ingredient: egg whites\n",
    "    quantity: 9\n",
    "  - ingredient: Cream of Tartar\n",
    "    quantity: 3/8 tsp\n",
    "  - ingredient: Vinegar\n",
    "    quantity: 1 1/2 tbs\n",
    "  - ingredient: Vanilla\n",
    "    quantity: 1 1/2 tsp\n",
    "  - ingredient: Sugar\n",
    "    quantity: 3 cups\n",
    "  - ingredient: Heavy whipping cream\n",
    "    quantity: 1 quarts\n",
    "  - ingredient: Strawberries\n",
    "    quantity: 3 boxes\n",
    "    \n",
    "    \n",
    "Text: Recipe for thanksgiving dinner\n",
    "Ingredients:\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
    "    ).text\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent work. You have now demonstrated your ability to use many key features in Google's PaLM library. Nice job.We likely want some nice wrapup here, but I don't know what, ha"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_palm_api.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": ".m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
