{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ur8xi4C7S06n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Ideation with Generative Models on Vertex AI\n",
    "\n",
    "> **NOTE:** This notebook uses the PaLM generative model, which will reach its [discontinuation date in October 2024](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text#model_versions). Please refer to [this updated notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/examples/ideation.ipynb) for a version which uses the latest Gemini model.\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/prompts/examples/ideation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/prompts/examples/ideation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/language/prompts/examples/ideation.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | |\n",
    "|-|-|\n",
    "|Author(s) | [Polong Lin](https://github.com/polong-lin) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Ideation is the creative process of generating, developing, and communicating new ideas. It is a key part of the design thinking process, and can be used to solve problems, come up with new products or services, or other creative tasks.\n",
    "\n",
    "Generative models are a powerful tool that can be used to boost creativity and innovation. By learning how to use them effectively, you can improve your ability to come up with new ideas and solutions to problems. A key part in this is learning how to structure prompts to use generative models for ideation tasks.\n",
    "\n",
    "Learn more about prompt design in the [official documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-overview#prompt_structure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you will learn how to use generative models from the Vertex AI SDK to accelerate the ideation process by working through the following examples:\n",
    "- Marketing campaign generation\n",
    "- Creating reading comprehension questions\n",
    "- Meme generation\n",
    "- Interview question generation\n",
    "- Name generation\n",
    "- General tips and advice\n",
    "- Generating answers through \"impersonation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aed92deeb4a0"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI Generative AI Studio\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
    "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwfLa-Uzua-4"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a5AEr0lkLKD"
   },
   "source": [
    "### Install Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "148dd6321946",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.60.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.63.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.32.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.5)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.5)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.17)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.1)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.25.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.7.4)\n",
      "Downloading google_cloud_aiplatform-1.63.0-py2.py3-none-any.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-cloud-aiplatform\n",
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed google-cloud-aiplatform-1.63.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-aiplatform --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Colab only:** Uncomment the following cell to restart the kernel or use the button to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_Hsqwn4hkLKE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe7OuYuGkLKF"
   },
   "source": [
    "### Authenticating your notebook environment\n",
    "* If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n",
    "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U9Gx2SAZkLKF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Colab only:** Uncomment the following cell to initialize the Vertex AI SDK. For Vertex AI Workbench, you don't need to run this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import vertexai\n",
    "\n",
    "# PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "# vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PyQmSRbKA8r-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UP76a2la7O-a"
   },
   "source": [
    "### Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7isig7e07O-a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724714100.274316     525 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n"
     ]
    }
   ],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoYLyYlLxN72"
   },
   "source": [
    "## Ideation Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Km9MirdFua-5"
   },
   "source": [
    "### Marketing campaign generation\n",
    "\n",
    "In this example, our generation example will involve the process of creating new cookie recipes. Let's see how this can be done using the PaLM API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "q2v5Pdkdua-6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " **Campaign Name:** \"Fashion Forward: Sustainable Style\"\n",
      "\n",
      "**Target Audience:** Millennial and Gen Z consumers who are interested in fashion and sustainability.\n",
      "\n",
      "**Campaign Goals:**\n",
      "\n",
      "* Increase awareness of the environmental impact of the fashion industry.\n",
      "* Educate consumers about sustainable fashion options.\n",
      "* Encourage consumers to make more sustainable fashion choices.\n",
      "\n",
      "**Campaign Strategies:**\n",
      "\n",
      "* Create a series of social media posts and blog articles that highlight the environmental impact of the fashion industry and provide tips for making more sustainable fashion choices.\n",
      "* Partner with sustainable fashion brands to offer discounts and promotions to consumers who purchase their products.\n",
      "* Host a series of workshops and events that teach consumers about sustainable fashion and how to make their own sustainable fashion choices.\n",
      "* Create a line of sustainable fashion products that are made from recycled materials and produced in a sustainable way.\n",
      "\n",
      "**Campaign Timeline:**\n",
      "\n",
      "The campaign will run for six months, from January to June 2023.\n",
      "\n",
      "**Campaign Budget:**\n",
      "\n",
      "The campaign budget is $50,000.\n",
      "\n",
      "**Campaign Evaluation:**\n",
      "\n",
      "The success of the campaign will be evaluated based on the following metrics:\n",
      "\n",
      "* Number of social media impressions and engagements\n",
      "* Number of blog article views\n",
      "* Number of workshop and event attendees\n",
      "* Sales of sustainable fashion products\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "The \"Fashion Forward: Sustainable Style\" campaign is a comprehensive marketing campaign that aims to increase awareness of the environmental impact of the fashion industry, educate consumers about sustainable fashion options, and encourage consumers to make more sustainable fashion choices. The campaign will use a variety of strategies to reach its target audience and achieve its goals.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Generate a marketing campaign for sustainability and fashion\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DC1rKWlua-6"
   },
   "source": [
    "### Creating reading comprehension questions\n",
    "\n",
    "Reading comprehension tests are often used in schools and universities to assess a student's reading skills. You can use the PaLM API to generate some example questions to test a person's understanding of a provided passage of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Shb54o4vua-6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. What percentage of the Amazon rainforest is located in Brazil?\n",
      "2. How many indigenous territories are there in the Amazon rainforest?\n",
      "3. What is the estimated number of individual trees in the Amazon rainforest?\n",
      "4. What is the name of the satellite that measures the amount of dust transported by wind from the Sahara to the Amazon?\n",
      "5. What is the name of the region in Africa that is a source of phosphorus for the Amazon rainforest?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Generate 5 questions that test a reader's comprehension of the following text.\n",
    "\n",
    "Text:\n",
    "The Amazon rainforest, also called Amazon jungle or Amazonia, is a moist broadleaf tropical rainforest in the Amazon biome that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 km2 (2,700,000 sq mi), of which 5,500,000 km2 (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations and 3,344 formally acknowledged indigenous territories.\n",
    "\n",
    "The majority of the forest, 60%, is in Brazil, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Bolivia, Ecuador, French Guiana, Guyana, Suriname, and Venezuela. Four nations have \"Amazonas\" as the name of one of their first-level administrative regions, and France uses the name \"Guiana Amazonian Park\" for French Guiana's protected rainforest area. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees in about 16,000 species.\n",
    "\n",
    "More than 30 million people of 350 different ethnic groups live in the Amazon, which are subdivided into 9 different national political systems and 3,344 formally acknowledged indigenous territories. Indigenous peoples make up 9% of the total population, and 60 of the groups remain largely isolated.\n",
    "\n",
    "The rainforest likely formed during the Eocene era (from 56 million years to 33.9 million years ago). It appeared following a global reduction of tropical temperatures when the Atlantic Ocean had widened sufficiently to provide a warm, moist climate to the Amazon basin. The rainforest has been in existence for at least 55 million years, and most of the region remained free of savanna-type biomes at least until the current ice age when the climate was drier and savanna more widespread.\n",
    "\n",
    "Following the Cretaceous–Paleogene extinction event, the extinction of the dinosaurs and the wetter climate may have allowed the tropical rainforest to spread out across the continent. From 66 to 34 Mya, the rainforest extended as far south as 45°. Climate fluctuations during the last 34 million years have allowed savanna regions to expand into the tropics. During the Oligocene, for example, the rainforest spanned a relatively narrow band. It expanded again during the Middle Miocene, then retracted to a mostly inland formation at the last glacial maximum. However, the rainforest still managed to thrive during these glacial periods, allowing for the survival and evolution of a broad diversity of species.\n",
    "\n",
    "Aerial view of the Amazon rainforest\n",
    "During the mid-Eocene, it is believed that the drainage basin of the Amazon was split along the middle of the continent by the Púrus Arch. Water on the eastern side flowed toward the Atlantic, while to the west water flowed toward the Pacific across the Amazonas Basin. As the Andes Mountains rose, however, a large basin was created that enclosed a lake; now known as the Solimões Basin. Within the last 5–10 million years, this accumulating water broke through the Púrus Arch, joining the easterly flow toward the Atlantic.\n",
    "\n",
    "There is evidence that there have been significant changes in the Amazon rainforest vegetation over the last 21,000 years through the last glacial maximum (LGM) and subsequent deglaciation. Analyses of sediment deposits from Amazon basin paleolakes and the Amazon Fan indicate that rainfall in the basin during the LGM was lower than for the present, and this was almost certainly associated with reduced moist tropical vegetation cover in the basin. In present day, the Amazon receives approximately 9 feet of rainfall annually. There is a debate, however, over how extensive this reduction was. Some scientists argue that the rainforest was reduced to small, isolated refugia separated by open forest and grassland; other scientists argue that the rainforest remained largely intact but extended less far to the north, south, and east than is seen today. This debate has proved difficult to resolve because the practical limitations of working in the rainforest mean that data sampling is biased away from the center of the Amazon basin, and both explanations are reasonably well supported by the available data.\n",
    "\n",
    "Sahara Desert dust windblown to the Amazon\n",
    "More than 56% of the dust fertilizing the Amazon rainforest comes from the Bodélé depression in Northern Chad in the Sahara desert. The dust contains phosphorus, important for plant growth. The yearly Sahara dust replaces the equivalent amount of phosphorus washed away yearly in Amazon soil from rains and floods.\n",
    "\n",
    "NASA's CALIPSO satellite has measured the amount of dust transported by wind from the Sahara to the Amazon: an average of 182 million tons of dust are windblown out of the Sahara each year, at 15 degrees west longitude, across 2,600 km (1,600 mi) over the Atlantic Ocean (some dust falls into the Atlantic), then at 35 degrees West longitude at the eastern coast of South America, 27.7 million tons (15%) of dust fall over the Amazon basin (22 million tons of it consisting of phosphorus), 132 million tons of dust remain in the air, 43 million tons of dust are windblown and falls on the Caribbean Sea, past 75 degrees west longitude.\n",
    "\n",
    "CALIPSO uses a laser range finder to scan the Earth's atmosphere for the vertical distribution of dust and other aerosols. CALIPSO regularly tracks the Sahara-Amazon dust plume. CALIPSO has measured variations in the dust amounts transported – an 86 percent drop between the highest amount of dust transported in 2007 and the lowest in 2011.\n",
    "A possibility causing the variation is the Sahel, a strip of semi-arid land on the southern border of the Sahara. When rain amounts in the Sahel are higher, the volume of dust is lower. The higher rainfall could make more vegetation grow in the Sahel, leaving less sand exposed to winds to blow away.[25]\n",
    "\n",
    "Amazon phosphorus also comes as smoke due to biomass burning in Africa.\n",
    "\n",
    "Questions:\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCcCMhbOua-7"
   },
   "source": [
    "### Meme generation\n",
    "\n",
    "A more lighthearted text generation example is to generate memes based on a certain topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6l_BZnx5ua-7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " **1.** A dog sitting at a table with a plate of food in front of it, looking very serious and focused. The caption could say something like \"When you're trying to eat your dinner but your dog is staring at you.\"\n",
      "\n",
      "**2.** A dog sitting on a couch with a remote control in its mouth, looking very relaxed. The caption could say something like \"When you're trying to watch TV but your dog has the remote.\"\n",
      "\n",
      "**3.** A dog standing in front of a mirror, looking very proud of itself. The caption could say something like \"When you're feeling good about yourself and you just have to show it off.\"\n",
      "\n",
      "**4.** A dog sitting in a box, looking very confused. The caption could say something like \"When you don't know what's going on but you're just going with it.\"\n",
      "\n",
      "**5.** A dog sitting on a person's lap, looking very happy and content. The caption could say something like \"When you're just happy to be loved.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Give me 5 dog meme ideas:\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt, temperature=0.2, max_output_tokens=1024, top_k=1, top_p=0.8\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9lnIlmWua-8"
   },
   "source": [
    "### Interview question generation\n",
    "\n",
    "Whether you are the interviewer or interviewee, having some sample interview questions you can work with can be very helpful in job interviews. Below we use the PaLM API to help us generate some potential interview questions for a particular role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xGrZMUt5ua-8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " **1.** What do you understand by the term \"prompt engineering\"?\n",
      "\n",
      "**2.** What are the different types of prompts that can be used in language models?\n",
      "\n",
      "**3.** How do you go about crafting effective prompts for a given task?\n",
      "\n",
      "**4.** What are some of the challenges and limitations of prompt engineering?\n",
      "\n",
      "**5.** How do you measure the success of a prompt?\n",
      "\n",
      "**6.** What are some of the best practices for prompt engineering?\n",
      "\n",
      "**7.** How do you stay up-to-date with the latest developments in prompt engineering?\n",
      "\n",
      "**8.** What are some of the ethical considerations that need to be taken into account when using prompt engineering?\n",
      "\n",
      "**9.** How do you handle situations where a prompt results in harmful or offensive output?\n",
      "\n",
      "**10.** What are your thoughts on the future of prompt engineering?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Give me ten interview questions for the role of prompt engineer.\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt, temperature=0.2, max_output_tokens=256, top_k=1, top_p=0.8\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1nSLoW7ua-8"
   },
   "source": [
    "### Name generation\n",
    "\n",
    "Name generation is useful in a variety of scenarios, such as creating new characters for a story or naming a new product or company. You can generate ideas for names of a specified entity using the PaLM API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qLnUrgs8ua-8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Everlasting Blooms\n",
      "* Dried Flower Delights\n",
      "* The Dried Flower Studio\n",
      "* The Pressed Petal\n",
      "* Nature's Everlasting Beauty\n",
      "* The Dried Flower Gallery\n",
      "* The Dried Flower Emporium\n",
      "* The Dried Flower Garden\n",
      "* The Dried Flower Boutique\n",
      "* The Dried Flower Market\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What's a good name for a flower shop that specializes in selling bouquets of dried flowers?\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt, temperature=0.2, max_output_tokens=256, top_k=1, top_p=0.8\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5Ca5Btvua-8"
   },
   "source": [
    "### General tips and advice\n",
    "\n",
    "Below is an example of using the PaLM API to get tips and advice on general topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aFy4ix6Cua-9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Overcoming writer's block requires a combination of techniques and mindset shifts. Here are some strategies to help you break through creative barriers:\n",
      "\n",
      "**1. Free Writing:**\n",
      "- Start by writing without any inhibitions or self-judgment. Let your thoughts flow freely onto the page.\n",
      "\n",
      "**2. Change of Environment:**\n",
      "- Move to a different location, such as a park, coffee shop, or library. A change of scenery can stimulate your creativity.\n",
      "\n",
      "**3. Mind Mapping:**\n",
      "- Create a visual representation of your ideas and concepts using a mind map. This can help you see connections and generate new ideas.\n",
      "\n",
      "**4. Prompts and Exercises:**\n",
      "- Use writing prompts or exercises to spark your creativity. There are many resources available online and in books.\n",
      "\n",
      "**5. Take a Break:**\n",
      "- Step away from your writing for a while. Go for a walk, listen to music, or engage in a different activity to refresh your mind.\n",
      "\n",
      "**6. Read and Research:**\n",
      "- Immerse yourself in reading related to your topic. New information can inspire fresh ideas and perspectives.\n",
      "\n",
      "**7. Talk It Out:**\n",
      "- Discuss your ideas with a friend, colleague, or writing group. Sometimes, talking about your work can help you gain clarity.\n",
      "\n",
      "**8. Set a Timer:**\n",
      "- Give yourself a specific time limit to write. This can help you focus and avoid overthinking.\n",
      "\n",
      "**9. Start Anywhere:**\n",
      "- Don't feel pressured to start at the beginning. Write about any aspect of your topic that interests you and connect the dots later.\n",
      "\n",
      "**10. Embrace Imperfection:**\n",
      "- Remember that your first draft doesn't have to be perfect. You can always revise and edit later.\n",
      "\n",
      "**11. Visualize Success:**\n",
      "- Imagine yourself successfully completing your writing project. Visualization can boost your motivation and confidence.\n",
      "\n",
      "**12. Seek Feedback:**\n",
      "- Share your work with a trusted friend, mentor, or writing group for feedback. Constructive criticism can help you identify areas for improvement.\n",
      "\n",
      "**13. Limit Distractions:**\n",
      "- Turn off notifications, close unnecessary tabs, and find a quiet place to write. Minimizing distractions can enhance your focus.\n",
      "\n",
      "**14. Practice Self-Compassion:**\n",
      "- Be kind to yourself and acknowledge that writer's block is a common experience. Don't let it discourage you.\n",
      "\n",
      "**15. Celebrate Progress:**\n",
      "- Acknowledge and celebrate even small achievements. Every word you write brings you closer to your goal.\n",
      "\n",
      "Remember that writer's block is temporary, and with persistence and the right strategies, you can overcome it and get back to your creative flow.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What are some strategies for overcoming writer's block?\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt, temperature=0.2, max_output_tokens=1024, top_k=1, top_p=0.8\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating answers through \"impersonation\"\n",
    "\n",
    "Below is an example for using PaLM API to impersonating a pirate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Avast ye! Be learnin' as if ye be livin' forever, but be livin' like ye be dyin' tomorrow! Harrr!\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"You are a pirate. Take the following sentence and rephrase it as a pirate.\n",
    "'Learn as if you will live forever, live like you will die tomorrow.' \n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt, temperature=0.8, max_output_tokens=1024, top_k=40, top_p=0.8\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ideation.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": ".m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
